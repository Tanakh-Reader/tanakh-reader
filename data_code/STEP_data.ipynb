{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import copy\n",
    "from tf.app import use\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTHT_FILE = '../data_files/STEP/TOTHT.csv'\n",
    "TOTHT_DF = pd.read_csv(TOTHT_FILE, sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBESH_FILE = '../data_files/STEP/TBESH.csv'\n",
    "TBESH_DF = pd.read_csv(TBESH_FILE, sep='\\t', low_memory=False, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "אָב\n"
     ]
    }
   ],
   "source": [
    "print(TBESH_DF.iloc[0]['lex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>strongs</th>\n",
       "      <th>lex</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>morph</th>\n",
       "      <th>gloss</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>H0001</td>\n",
       "      <td>אָב</td>\n",
       "      <td>av</td>\n",
       "      <td>H:N-M</td>\n",
       "      <td>father</td>\n",
       "      <td>1) father of an individual&lt;br&gt;2) of God as father of his people&lt;br&gt;3) head or founder of a household, group, family, or clan&lt;br&gt;4) ancestor&lt;br&gt;4a) grandfather, forefathers - of person&lt;br&gt;4b) of people&lt;br&gt;5) originator or patron of a class, profession, or art&lt;br&gt;6) of producer, generator (fig.)&lt;br&gt;7) of benevolence and protection (fig.)&lt;br&gt;8) term of respect and honour&lt;br&gt;9) ruler or chief (spec.)&lt;br&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>H0002</td>\n",
       "      <td>אַב</td>\n",
       "      <td>av</td>\n",
       "      <td>A:N-M</td>\n",
       "      <td>father</td>\n",
       "      <td>1) father&lt;br&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(TBESH_DF.head(n=2).to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_lex = [l for l in TBESH_DF['lex']]\n",
    "lex2 = set([i for i in OHB_ALIGNED['lex']])\n",
    "tb_str = [s for s in TBESH_DF['strongs']]\n",
    "lex_map = {tb_lex[i]:tb_str[i] for i in range(len(tb_lex))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_map = {tb_lex[i]:tb_str[i] for i in range(len(tb_lex))}\n",
    "for l in lex2:\n",
    "    if l not in lex_map:\n",
    "        print(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ref in Heb</th>\n",
       "      <th>Eng ref</th>\n",
       "      <th>Pointed</th>\n",
       "      <th>Accented</th>\n",
       "      <th>Morphology</th>\n",
       "      <th>Extended Strongs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-01</td>\n",
       "      <td>Gen.1.1-01</td>\n",
       "      <td>בְּרֵאשִׁית</td>\n",
       "      <td>בְּ/רֵאשִׁ֖ית</td>\n",
       "      <td>HR/Ncfsa</td>\n",
       "      <td>H9003=ב=in/H7225=רֵאשִׁית=first_§1_beginning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-02</td>\n",
       "      <td>Gen.1.1-02</td>\n",
       "      <td>בָּרָא</td>\n",
       "      <td>בָּרָ֣א</td>\n",
       "      <td>HVqp3ms</td>\n",
       "      <td>H1254a=בָּרָא=to create</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-03</td>\n",
       "      <td>Gen.1.1-03</td>\n",
       "      <td>אֱלֹהִים</td>\n",
       "      <td>אֱלֹהִ֑ים</td>\n",
       "      <td>HNcmpa</td>\n",
       "      <td>H0430=אֱלֹהִים=God_§God@Gen.1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-04</td>\n",
       "      <td>Gen.1.1-04</td>\n",
       "      <td>אֵת</td>\n",
       "      <td>אֵ֥ת</td>\n",
       "      <td>HTo</td>\n",
       "      <td>H0853=אֵת=obj.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-05</td>\n",
       "      <td>Gen.1.1-05</td>\n",
       "      <td>הַשָּׁמַיִם</td>\n",
       "      <td>הַ/שָּׁמַ֖יִם</td>\n",
       "      <td>HTd/Ncmpa</td>\n",
       "      <td>H9009=ה=the/H8064=שָׁמַיִם=heaven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-06</td>\n",
       "      <td>Gen.1.1-06</td>\n",
       "      <td>וְאֵת</td>\n",
       "      <td>וְ/אֵ֥ת</td>\n",
       "      <td>HC/To</td>\n",
       "      <td>H9002=ו=and/H0853=אֵת=obj.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-07</td>\n",
       "      <td>Gen.1.1-07</td>\n",
       "      <td>הָאָרֶץ</td>\n",
       "      <td>הָ/אָֽרֶץ/׃</td>\n",
       "      <td>HTd/Ncbsa</td>\n",
       "      <td>H9009=ה=the/H0776=אֶ֫רֶץ=land_§3_planet/H9016=׃=verseEnd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(TBESH_DF.head(n=7).to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 595\n",
    "display(HTML(TBESH_DF.loc[i:i+40].to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "׃\n"
     ]
    }
   ],
   "source": [
    "print(TBESH_DF.iloc[6]['Accented'].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(max([len(i.split('/')) for i in morph if type(i) == str]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424014 47377\n"
     ]
    }
   ],
   "source": [
    "# Word count for the dataset.\n",
    "morph = [i for i in TBESH_DF['Morphology']]\n",
    "count = 0\n",
    "suffix = 0\n",
    "for i in range(len(morph)):\n",
    "    count +=1\n",
    "    if type(morph[i]) == float:\n",
    "        pass\n",
    "    else:\n",
    "        data = morph[i].split('/')\n",
    "        if data[-1][0] in ['S']:\n",
    "            if len(data) == 1:\n",
    "                print(data)\n",
    "            count += len(data)-2\n",
    "            suffix += 1\n",
    "        else:\n",
    "            count += len(data)-1\n",
    "print(count, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'ref':[], 'word':[], 'lex':[], 'morph':[], 'strong':[], 'suffix':[], 'suffix_strong':[]}\n",
    "refs = [i for i in TBESH_DF['Ref in Heb']]\n",
    "words = [i for i in TBESH_DF['Accented']]\n",
    "morphs = [i for i in TBESH_DF['Morphology']]\n",
    "strongs = [i for i in TBESH_DF['Extended Strongs']]\n",
    "for i in range(len(refs)):\n",
    "    if type(words[i]) != str:\n",
    "        for k in data:\n",
    "            data[k].append(None)\n",
    "    else:\n",
    "        morph = morphs[i].split('/')\n",
    "        count = len(morph) \n",
    "        strong_data = strongs[i].split('/')\n",
    "        strong = []\n",
    "        lex = []\n",
    "        word = words[i].split('/')\n",
    "        if count > 1:\n",
    "            for s in strong_data:\n",
    "                sd = s.split('=')\n",
    "                if sd[0] not in ['_', '', ' ']:\n",
    "                    # print(i, sd)\n",
    "                    strong.append(sd[0])\n",
    "                    try:\n",
    "                        lex.append(sd[1])\n",
    "                    except IndexError:\n",
    "                        print(i, sd)\n",
    "                else:\n",
    "                    strong.append('')\n",
    "                    lex.append('')\n",
    "            if morph[-1][0] in ['S']:\n",
    "                for j, m in enumerate(morph[:-2]):\n",
    "                    data['ref'].append(refs[i])\n",
    "                    data['word'].append(word[j])\n",
    "                    data['lex'].append(lex[j])\n",
    "                    data['morph'].append(m)\n",
    "                    data['suffix'].append(None)\n",
    "                    data['strong'].append(strong[j])\n",
    "                    data['suffix_strong'].append(None)\n",
    "                data['ref'].append(refs[i])\n",
    "                data['word'].append(word[count-2]+word[count-1])\n",
    "                data['lex'].append(lex[count-2])\n",
    "                data['morph'].append(morph[-2])\n",
    "                data['suffix'].append(word[count-1])\n",
    "                data['strong'].append(strong[count-2])\n",
    "                data['suffix_strong'].append(strong[count-1])\n",
    "            else:\n",
    "                for j, m in enumerate(morph):\n",
    "                    data['ref'].append(refs[i])\n",
    "                    data['word'].append(word[j])\n",
    "                    data['lex'].append(lex[j])\n",
    "                    data['morph'].append(m)\n",
    "                    data['suffix'].append(None)\n",
    "                    data['strong'].append(strong[j])\n",
    "                    data['suffix_strong'].append(None)\n",
    "        else:\n",
    "            sd = strong_data[0].split('=')\n",
    "            strong.append(sd[0])\n",
    "            lex.append(sd[1])\n",
    "            data['ref'].append(refs[i])\n",
    "            data['word'].append(word[0])\n",
    "            data['lex'].append(lex[0])\n",
    "            data['morph'].append(morph[0])\n",
    "            data['suffix'].append(None)\n",
    "            data['strong'].append(strong[0])\n",
    "            data['suffix_strong'].append(None)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ref</th>\n",
       "      <th>word</th>\n",
       "      <th>lex</th>\n",
       "      <th>morph</th>\n",
       "      <th>strong</th>\n",
       "      <th>suffix</th>\n",
       "      <th>suffix_strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-01</td>\n",
       "      <td>בְּ</td>\n",
       "      <td>ב</td>\n",
       "      <td>HR</td>\n",
       "      <td>H9003</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-01</td>\n",
       "      <td>רֵאשִׁ֖ית</td>\n",
       "      <td>רֵאשִׁית</td>\n",
       "      <td>Ncfsa</td>\n",
       "      <td>H7225</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-02</td>\n",
       "      <td>בָּרָ֣א</td>\n",
       "      <td>בָּרָא</td>\n",
       "      <td>HVqp3ms</td>\n",
       "      <td>H1254a</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-03</td>\n",
       "      <td>אֱלֹהִ֑ים</td>\n",
       "      <td>אֱלֹהִים</td>\n",
       "      <td>HNcmpa</td>\n",
       "      <td>H0430</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-04</td>\n",
       "      <td>אֵ֥ת</td>\n",
       "      <td>אֵת</td>\n",
       "      <td>HTo</td>\n",
       "      <td>H0853</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-05</td>\n",
       "      <td>הַ</td>\n",
       "      <td>ה</td>\n",
       "      <td>HTd</td>\n",
       "      <td>H9009</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-05</td>\n",
       "      <td>שָּׁמַ֖יִם</td>\n",
       "      <td>שָׁמַיִם</td>\n",
       "      <td>Ncmpa</td>\n",
       "      <td>H8064</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-06</td>\n",
       "      <td>וְ</td>\n",
       "      <td>ו</td>\n",
       "      <td>HC</td>\n",
       "      <td>H9002</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-06</td>\n",
       "      <td>אֵ֥ת</td>\n",
       "      <td>אֵת</td>\n",
       "      <td>To</td>\n",
       "      <td>H0853</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Gen.1.1-07</td>\n",
       "      <td>הָ</td>\n",
       "      <td>ה</td>\n",
       "      <td>HTd</td>\n",
       "      <td>H9009</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(df.head(n=10).to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424014\n"
     ]
    }
   ],
   "source": [
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/yakovsh/345a71d841871cc3d375\n",
    "# Convert pointed text to consonantal. \n",
    "from unicodedata import normalize, combining\n",
    "def norm(w):\n",
    "    normalized = normalize('NFKD', w) # Reduce hebrew vowel ניקוד marks\n",
    "    flattened = ''.join([c for c in normalized if not combining(c)])\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1715, 1810):\n",
    "    print(i, lex1[i], lex2[i+18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex1 = [i for i in df['lex']]\n",
    "lex2 = [i for i in OHB_ALIGNED['lex']]\n",
    "words2 = [i for i in OHB_ALIGNED['word']]\n",
    "k = 0\n",
    "x = 0\n",
    "count = 0\n",
    "print(len(lex1))\n",
    "for i, l in enumerate(lex1):\n",
    "    j = i+k\n",
    "    z = i+x\n",
    "    l = norm(lex1[z]) if l else ''\n",
    "    l2 = norm(lex2[j]) if lex2[j] else ''\n",
    "    if type(words2[j]) != str:\n",
    "        print('XX', i, l, l2)\n",
    "        k += 1\n",
    "    elif l[:2] != l2[:2]:\n",
    "        if l2 in ['למה', 'לכן']:\n",
    "            x += 1\n",
    "        else:\n",
    "            count += 1\n",
    "            print(i, lex1[z-3:z+3], '\\n', lex2[j-3:j+3])\n",
    "            print(l, l2)\n",
    "    if i % 10000 == 0:\n",
    "        print(i, l, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 15\n"
     ]
    }
   ],
   "source": [
    "nan = 0\n",
    "emp = 0\n",
    "for i in words:\n",
    "    if i == '':\n",
    "        emp += 1\n",
    "    if type(i) != str:\n",
    "        nan +=1\n",
    "print(emp, nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data_files/Combined/ohb_combined_aligned.csv'\n",
    "OHB_ALIGNED = pd.read_csv(file, sep=',', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1380\n",
    "display(HTML(TBESH_DF.loc[i-5:i+5].to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2012\n",
    "display(HTML(df.loc[i-5:i+5].to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1755\n",
    "display(HTML(OHB_ALIGNED.loc[i-5:i+5].to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [i for i in df['word']]\n",
    "words2 = [i for i in OHB_ALIGNED['word']]\n",
    "count = 0\n",
    "for i, w in enumerate(words2):\n",
    "    if w != words[i]:\n",
    "        print(i, w, '\\n', words[i])\n",
    "        count += 1\n",
    "    if count > 20:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
