{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenHebrewBible (OHB) CSV Data to SQL Conversion\n",
    "\n",
    "Eliran Wong used date from [ETCBC](https://github.com/ETCBC/bhsa) (Hebrew text BHSA, linguitic annotations, morphology, etc.), [OpenScriptures](https://github.com/openscriptures/morphhb) (Hebrew text WLC, Strong's numbers, morphology, etc.), and [Berean.bible](https://berean.bible) (interlinear translation, Berean Study Bible, etc.) to create a robust data repository called [OpenHebrewBible](https://github.com/eliranwong/OpenHebrewBible), consisting of CSV files that bridge the other three open-source projects.\n",
    "\n",
    "I will take his compiled data file, [BHSA-with-extended-features.csv](https://github.com/eliranwong/OpenHebrewBible/blob/master/BHSA-with-extended-features.csv.zip), clean it, and convert it into a SQL database that I can use in my Flutter app. \n",
    "\n",
    "Later I will compare the converted SQL database to a BHSA SQL file, which can be downloaded [here](https://www.adambaker.org/bhsa.sqlite).\n",
    "\n",
    "### Why uses OHB data when BHSA already exists?\n",
    "Some features that could be useful from OHB data that aren't present in BHSA are:\n",
    "- Strong's number mapped to each node in the BHS.\n",
    "- Data to align the BHS text with KJV and BSB translations.\n",
    "- Poetice devisions (not tested).\n",
    "- BSB gloss for a more accurate rendering of each word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements: run in terminal. Change to 'pip' if on Windows OS. \n",
    "\"\"\"\n",
    "pip3 install pandas\n",
    "pip3 install numpy\n",
    "pip3 install text-fabric\n",
    "pip3 install jupyter\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import copy\n",
    "from tf.app import use\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "The extended BHSA file consists of all the individual Hebrew words in the BHS text. It has 22 feature columns and uses tab-separeted delineation. All of the data consists of strings or positive integers. \n",
    "\n",
    "You can view the first two rows (1: column names, 2: data) of the file below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>BHSwordSort</th>\n",
       "      <th>paragraphMarker</th>\n",
       "      <th>poetryMarker</th>\n",
       "      <th>〔KJVverseSort｜KJVbook｜KJVchapter｜KJVverse〕</th>\n",
       "      <th>〔BHSverseSort｜BHSbook｜BHSchapter｜BHSverse〕</th>\n",
       "      <th>clauseID</th>\n",
       "      <th>clauseKind</th>\n",
       "      <th>clauseType</th>\n",
       "      <th>language</th>\n",
       "      <th>BHSwordPointed</th>\n",
       "      <th>BHSwordConsonantal</th>\n",
       "      <th>SBLstyleTransliteration</th>\n",
       "      <th>poneticTranscription</th>\n",
       "      <th>HebrewLexeme</th>\n",
       "      <th>lexemeID</th>\n",
       "      <th>StrongNumber</th>\n",
       "      <th>extendedStrongNumber</th>\n",
       "      <th>morphologyCode</th>\n",
       "      <th>morphologyDetail</th>\n",
       "      <th>ETCBCgloss</th>\n",
       "      <th>extendedGloss</th>\n",
       "      <th>〔BSBsort＠BSB〕</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>¶</td>\n",
       "      <td>NaN</td>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>c1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>&lt;heb&gt;בְּ&lt;/heb&gt;&lt;heb&gt;&lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;ב&lt;/heb&gt;&lt;heb&gt;&lt;/heb&gt;</td>\n",
       "      <td>bĕ</td>\n",
       "      <td>bᵊ</td>\n",
       "      <td>&lt;heb&gt;בְּ&lt;/heb&gt;</td>\n",
       "      <td>E70001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H9003</td>\n",
       "      <td>prep</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>〔1＠In〕</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the extended.csv file to a pandas dataframe.\n",
    "csv_file = '../data_files/BHSA-with-extended-features.csv'\n",
    "# Set low_memory to False to deal with unexpected data types. \n",
    "# Converts those data to NaN.\n",
    "df = pd.read_csv(csv_file, sep='\\t', low_memory=False)\n",
    "\n",
    "# View the first two rows of our dataframe. \n",
    "display(HTML(df.head(n=1).to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to clean:\n",
    "```\n",
    "- 〔KJVverseSort｜KJVbook｜KJVchapter｜KJVverse〕: remove chars and place ints in new columns\n",
    "- 〔BHSverseSort｜BHSbook｜BHSchapter｜BHSverse〕: remove chars and place ints in new columns\n",
    "-  clauseID : remove 'c' prefix and convert to int\n",
    "-  BHSwordPointed : remove html tags, place word and suffix in list\n",
    "-  BHSwordConsonantal : remove html tags, place word and suffix in list\n",
    "-  HebrewLexeme : remove html tags\n",
    "- 〔BSBsort＠BSB〕: remove chars and place int and string in new columns\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean Text and Clause Data\n",
    "\n",
    "** **Important note:** certain nodes do not have a text value for *BHSwordPointed* or *BHSWordConsonantal* because of the nature of the Hebrew language. For example at BHS word node values 61-62 we have:\n",
    "```\n",
    "61  <heb>לָ</heb><heb></heb>     <heb>ל</heb><heb></heb>     <heb>לְ</heb>    H9005   prep    to\t\n",
    "62  <heb></heb><heb></heb>      <heb></heb><heb></heb>      <heb>הַ</heb>    H9009   art     the\t〔51＠the〕\n",
    "```\n",
    "This if from a clause in Genesis 5:1, with the Hebrew: וַיִּקְרָא אֱלֹהִים לָאוֹר יוֹם\n",
    "\n",
    "Node 62 is embedded into the word לָאוֹר, attached to the preoposition via a patach, but the *he* (the) doesn't appear consonantaly in the text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize pre-cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>BHSwordPointed</th>\n",
       "      <th>BHSwordConsonantal</th>\n",
       "      <th>HebrewLexeme</th>\n",
       "      <th>clauseID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>&lt;heb&gt;בְּ&lt;/heb&gt;&lt;heb&gt;&lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;ב&lt;/heb&gt;&lt;heb&gt;&lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;בְּ&lt;/heb&gt;</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;heb&gt;רֵאשִׁ֖ית&lt;/heb&gt;&lt;heb&gt; &lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;ראשית&lt;/heb&gt;&lt;heb&gt; &lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;רֵאשִׁית&lt;/heb&gt;</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;heb&gt;בָּרָ֣א&lt;/heb&gt;&lt;heb&gt; &lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;ברא&lt;/heb&gt;&lt;heb&gt; &lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;ברא&lt;/heb&gt;</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;heb&gt;אֱלֹהִ֑ים&lt;/heb&gt;&lt;heb&gt; &lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;אלהים&lt;/heb&gt;&lt;heb&gt; &lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;אֱלֹהִים&lt;/heb&gt;</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;heb&gt;אֵ֥ת&lt;/heb&gt;&lt;heb&gt; &lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;את&lt;/heb&gt;&lt;heb&gt; &lt;/heb&gt;</td>\n",
       "      <td>&lt;heb&gt;אֵת&lt;/heb&gt;</td>\n",
       "      <td>c1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data before being cleaned.\n",
    "display(HTML(\n",
    "    df[\n",
    "        [\"BHSwordPointed\", \n",
    "        \"BHSwordConsonantal\", \n",
    "        \"HebrewLexeme\", \n",
    "        \"clauseID\"]\n",
    "    ].head().to_html(index=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textual items in between word nodes, including paragraph markers, etc. \n",
    "text_extensions = {\n",
    "    '', '׃', '׃ ׆ ס ', ' ס ', '׃ ׆ ', '׃ ', ' ׀ ',\n",
    "    ' ', '׃ פ ', ' פ ', '׀ ', '׃ ׆ פ ', '־', '׃ ס '\n",
    "}\n",
    "\n",
    "# ---\n",
    "# Function that takes a column name from the original df and\n",
    "# returns cleaned text (word and extension) separated by |.\n",
    "# Use: BHS pointed and consonantal text, all of which is of a format similar\n",
    "# to : <heb>הָ</heb><heb></heb>. Be sure to update the df with the return value. \n",
    "def clean_text(col_name):\n",
    "    cleaned_text = []\n",
    "    # All of the junk html text present.\n",
    "    remove_items = \"/<arc>hebqrQR\"\n",
    "    # Either of these will appear between the word and extension.\n",
    "    seperator = [\"</heb><heb>\", \"</arc><arc>\"]\n",
    "    # Iterate over the original dataframe and clean the data. \n",
    "    for text_data in df[col_name]:\n",
    "        # Place | at center so we can later split the text data. \n",
    "        for sep in seperator:\n",
    "            if sep in text_data:\n",
    "                text_data = text_data.replace(sep, '|')\n",
    "        # Remove all extra items.\n",
    "        for char in remove_items:\n",
    "            if char in text_data:\n",
    "                text_data = text_data.replace(char, \"\")\n",
    "\n",
    "        # Note: I originally split each text and stored it in a list before \n",
    "        # appending to cleaned_text, but that caused an error when uploading \n",
    "        # to SQL because it needed an actual data type (e.g., string).\n",
    "        \n",
    "        # Add a text separated by | to cleaned text where pre '|' is \n",
    "        # a Heb word and post '|' is the extension.\n",
    "        cleaned_text.append(text_data)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# ---\n",
    "# Clean the text in the HebrewLexem column, all of which is\n",
    "# in a format similar to: <heb>הָ</heb>. \n",
    "def clean_lexemes(col_name):\n",
    "    cleaned_text = []\n",
    "    # Read comments from clean_text()\n",
    "    remove_items = \"/<arc>hebqrQR\"\n",
    "    # Iterate over the original dataframe and clean the data. \n",
    "    for text_data in df[col_name]:\n",
    "        # Remove all extra items.\n",
    "        for char in remove_items:\n",
    "            if char in text_data:\n",
    "                text_data = text_data.replace(char, \"\")\n",
    "        # Add the lexeme to the cleaned data.\n",
    "        cleaned_text.append(text_data)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "# ---\n",
    "# All clause data is of the format: c12. Remove the 'c's\n",
    "# in the clause data and convert to int type. \n",
    "def clean_clauses(col_name):\n",
    "    cleaned_ids = []\n",
    "    # Iterate over the original dataframe and clean the data. \n",
    "    for clause in df[col_name]:\n",
    "        cleaned_ids.append(int(clause.strip(\"c\")))\n",
    "        \n",
    "    return cleaned_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Call the functions -> update dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the data frame with the cleaned text and clauses. \n",
    "df[\"BHSwordPointed\"] = clean_text(\"BHSwordPointed\")\n",
    "df[\"BHSwordConsonantal\"] = clean_text(\"BHSwordConsonantal\")\n",
    "df[\"HebrewLexeme\"] = clean_lexemes(\"HebrewLexeme\")\n",
    "df[\"clauseID\"] = clean_clauses(\"clauseID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>BHSwordPointed</th>\n",
       "      <th>BHSwordConsonantal</th>\n",
       "      <th>HebrewLexeme</th>\n",
       "      <th>clauseID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>בְּ|</td>\n",
       "      <td>ב|</td>\n",
       "      <td>בְּ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>רֵאשִׁ֖ית|</td>\n",
       "      <td>ראשית|</td>\n",
       "      <td>רֵאשִׁית</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>בָּרָ֣א|</td>\n",
       "      <td>ברא|</td>\n",
       "      <td>ברא</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>אֱלֹהִ֑ים|</td>\n",
       "      <td>אלהים|</td>\n",
       "      <td>אֱלֹהִים</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>אֵ֥ת|</td>\n",
       "      <td>את|</td>\n",
       "      <td>אֵת</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the head with the cleaned data.\n",
    "display(HTML(\n",
    "    df[\n",
    "        [\"BHSwordPointed\", \n",
    "        \"BHSwordConsonantal\", \n",
    "        \"HebrewLexeme\", \n",
    "        \"clauseID\"]\n",
    "    ].head().to_html(index=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Expand KJV, BHS, and BSB columns\n",
    "\n",
    "In the original 22 columns there are three features that consist of concatenated values:\n",
    "\n",
    "- 〔KJVverseSort｜KJVbook｜KJVchapter｜KJVverse〕:〔1｜1｜1｜1〕  \n",
    "- 〔BHSverseSort｜BHSbook｜BHSchapter｜BHSverse〕:〔1｜1｜1｜1〕\n",
    "- 〔BSBsort＠BSB〕:〔1＠In〕\n",
    "\n",
    "I will convert each of them to new dataframes with separate columns for each value, and then merge them back into the original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize pre-cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>〔KJVverseSort｜KJVbook｜KJVchapter｜KJVverse〕</th>\n",
       "      <th>〔BHSverseSort｜BHSbook｜BHSchapter｜BHSverse〕</th>\n",
       "      <th>〔BSBsort＠BSB〕</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔1＠In〕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔2＠the beginning〕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔4＠created〕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔3＠God〕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>〔1｜1｜1｜1〕</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data before being cleaned.\n",
    "display(HTML(\n",
    "    df[\n",
    "        ['〔KJVverseSort｜KJVbook｜KJVchapter｜KJVverse〕', \n",
    "        '〔BHSverseSort｜BHSbook｜BHSchapter｜BHSverse〕',\n",
    "        '〔BSBsort＠BSB〕']\n",
    "    ].head().to_html(index=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where the value is a list, convert the original \n",
    "# column to len(list) new columns. \n",
    "updated_col_names = {\n",
    "    'BHSwordSort': # no cleaning\n",
    "        'BHS_wordNode', \n",
    "    '〔KJVverseSort｜KJVbook｜KJVchapter｜KJVverse〕': # cleaned\n",
    "        ['KVJvsNode', 'KJVbook', 'KJVchapter', 'KJVverse'], \n",
    "    '〔BHSverseSort｜BHSbook｜BHSchapter｜BHSverse〕': # cleaned\n",
    "        ['BHSvsNode', 'BHSbook', 'BHSchapter', 'BHSverse'], \n",
    "    'BHSwordPointed': # cleaned\n",
    "        'BHS_wordPointed', \n",
    "    'BHSwordConsonantal': # no cleaning\n",
    "        'BHS_wordConsonantal',\n",
    "    'poneticTranscription': # no cleaning\n",
    "        'phoneticTranscription',\n",
    "    '〔BSBsort＠BSB〕': # cleaned\n",
    "        ['BSBglossNode', 'BSBgloss']\n",
    "}\n",
    "\n",
    "# ---\n",
    "# Function that takes a column name from \n",
    "# the original df and returns cleaned data.\n",
    "# Use: convert the KJF ref or BHS ref column to new dataframe. \n",
    "def clean_references(col_name):\n",
    "    # Create a dict for each new name to the new values.\n",
    "    new_names = updated_col_names[col_name]\n",
    "    cleaned_data = {name:[] for name in new_names}\n",
    "    # Iterate over the original dataframe and clean the data. \n",
    "    for ref_data in df[col_name]:\n",
    "        # Remove the outsides of 〔1｜1｜1｜1〕.\n",
    "        ref_data = ref_data.strip('〕〔')\n",
    "        # Split 1｜1｜1｜1 and convert each item to an int.\n",
    "        ref_data = [int(data) for data in ref_data.split('｜')]\n",
    "        # Add data to the dictionary. \n",
    "        cleaned_data[new_names[0]].append(ref_data[0]) # vs node\n",
    "        cleaned_data[new_names[1]].append(ref_data[1]) # book\n",
    "        cleaned_data[new_names[2]].append(ref_data[2]) # chapter\n",
    "        cleaned_data[new_names[3]].append(ref_data[3]) # verse\n",
    "   \n",
    "    # Convert the dictionary to a dataframe and return.\n",
    "    new_df = pd.DataFrame(cleaned_data)\n",
    "    return new_df\n",
    "\n",
    "# ---\n",
    "# Clean the BSB gloss data and store in a new dataframe. \n",
    "def clean_gloss(col_name):\n",
    "    # Create a dict for each new name to the new values.\n",
    "    new_names = updated_col_names[col_name]\n",
    "    cleaned_data = {name:[] for name in new_names}\n",
    "    # Iterate over the original dataframe and clean the data. \n",
    "    for gloss_data in df[col_name]:\n",
    "        # Catch edge cases where gloss_data is NaN.\n",
    "        if isinstance(gloss_data, str):\n",
    "            # Remove the outsides of 〔1＠In〕.\n",
    "            gloss_data = gloss_data.strip('〕〔')\n",
    "            # Split 1＠In and convert first item to an int.\n",
    "            gloss_data = gloss_data.split('＠')\n",
    "            \n",
    "            # For some reason, gloss node 237839 is split into \n",
    "            # decimals .1 and .2, which is why I am using a float. \n",
    "\n",
    "            # Add data to the dictionary. \n",
    "            gloss_data[0] = float(gloss_data[0])\n",
    "            cleaned_data[new_names[0]].append(gloss_data[0]) # gloss node\n",
    "            cleaned_data[new_names[1]].append(gloss_data[1]) # gloss\n",
    "        else:\n",
    "            cleaned_data[new_names[0]].append(gloss_data) # gloss node\n",
    "            cleaned_data[new_names[1]].append(gloss_data) # gloss\n",
    "\n",
    "    # Convert the dictionary to a dataframe and return.\n",
    "    new_df = pd.DataFrame(cleaned_data)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Call the functions -> new dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the reference data and store in two new dataframes. \n",
    "KJV_ref_df = clean_references(\n",
    "    '〔KJVverseSort｜KJVbook｜KJVchapter｜KJVverse〕')\n",
    "BHS_ref_df = clean_references(\n",
    "    '〔BHSverseSort｜BHSbook｜BHSchapter｜BHSverse〕')\n",
    "BSB_gloss_df = clean_gloss(\n",
    "    '〔BSBsort＠BSB〕')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>KVJvsNode</th>\n",
       "      <th>KJVbook</th>\n",
       "      <th>KJVchapter</th>\n",
       "      <th>KJVverse</th>\n",
       "      <th>BHSvsNode</th>\n",
       "      <th>BHSbook</th>\n",
       "      <th>BHSchapter</th>\n",
       "      <th>BHSverse</th>\n",
       "      <th>BSBglossNode</th>\n",
       "      <th>BSBgloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>the beginning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the head of the cleaned data.\n",
    "display(HTML(\n",
    "    pd.concat(\n",
    "        [KJV_ref_df, \n",
    "        BHS_ref_df, \n",
    "        BSB_gloss_df],\n",
    "        axis=1\n",
    "    ).head().to_html(index=False))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Rename columns and combine dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Drop the three columns that I expanded into new dataframes.\n",
    "def drop_old_data(dateframe):\n",
    "    dateframe = dateframe.drop(\n",
    "        columns=[\n",
    "        '〔KJVverseSort｜KJVbook｜KJVchapter｜KJVverse〕', \n",
    "        '〔BHSverseSort｜BHSbook｜BHSchapter｜BHSverse〕',\n",
    "        '〔BSBsort＠BSB〕']\n",
    "    )\n",
    "    return dateframe\n",
    "\n",
    "# ---\n",
    "# Rename certaine columns and add the three \n",
    "# new dataframes for a final df output. \n",
    "def combine_data():\n",
    "    df_copy = copy.deepcopy(df)\n",
    "    updated_df = pd.DataFrame()\n",
    "    # Make sure the replaced data gets dropped. \n",
    "    if \"〔BSBsort＠BSB〕\" in df_copy.columns:\n",
    "        df_copy = drop_old_data(df_copy)\n",
    "    # Rename the other columns and build updated_df.\n",
    "    for column in df_copy:\n",
    "        # Simply add the renamed column if it's in our dictionary. \n",
    "        if column in updated_col_names:\n",
    "            updated_df[updated_col_names[column]] = df[column]\n",
    "        # If column isn't in our dictionary, add new dfs or\n",
    "        # simply add the current column. \n",
    "        else:\n",
    "            # If at the column before 〔KJVverseSort..., \n",
    "            # add the new reference dataframes.\n",
    "            if column == \"poetryMarker\":\n",
    "                updated_df = pd.concat(\n",
    "                    [updated_df, \n",
    "                    df_copy[column], \n",
    "                    KJV_ref_df, \n",
    "                    BHS_ref_df], \n",
    "                    axis=1)\n",
    "            # If at the column before 〔BSBsort..., \n",
    "            # add the new BSB dataframe.\n",
    "            elif column == \"extendedGloss\":\n",
    "                updated_df = pd.concat(\n",
    "                    [updated_df, \n",
    "                    df_copy[column], \n",
    "                    BSB_gloss_df], \n",
    "                    axis=1)\n",
    "            # Otherwise add the current column \n",
    "            # from the original dataframe.\n",
    "            else:\n",
    "                updated_df[column] = df_copy[column]\n",
    "\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Call function -> combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the combined data in a new dataframe. \n",
    "updated_data = combine_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Finally - Replace NaN values with \"\" to match string data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize pre-cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>BHS_wordNode</th>\n",
       "      <th>paragraphMarker</th>\n",
       "      <th>poetryMarker</th>\n",
       "      <th>KVJvsNode</th>\n",
       "      <th>KJVbook</th>\n",
       "      <th>KJVchapter</th>\n",
       "      <th>KJVverse</th>\n",
       "      <th>BHSvsNode</th>\n",
       "      <th>BHSbook</th>\n",
       "      <th>BHSchapter</th>\n",
       "      <th>BHSverse</th>\n",
       "      <th>clauseID</th>\n",
       "      <th>clauseKind</th>\n",
       "      <th>clauseType</th>\n",
       "      <th>language</th>\n",
       "      <th>BHS_wordPointed</th>\n",
       "      <th>BHS_wordConsonantal</th>\n",
       "      <th>SBLstyleTransliteration</th>\n",
       "      <th>phoneticTranscription</th>\n",
       "      <th>HebrewLexeme</th>\n",
       "      <th>lexemeID</th>\n",
       "      <th>StrongNumber</th>\n",
       "      <th>extendedStrongNumber</th>\n",
       "      <th>morphologyCode</th>\n",
       "      <th>morphologyDetail</th>\n",
       "      <th>ETCBCgloss</th>\n",
       "      <th>extendedGloss</th>\n",
       "      <th>BSBglossNode</th>\n",
       "      <th>BSBgloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>¶</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>בְּ|</td>\n",
       "      <td>ב|</td>\n",
       "      <td>bĕ</td>\n",
       "      <td>bᵊ</td>\n",
       "      <td>בְּ</td>\n",
       "      <td>E70001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H9003</td>\n",
       "      <td>prep</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>רֵאשִׁ֖ית|</td>\n",
       "      <td>ראשית|</td>\n",
       "      <td>rēšît</td>\n",
       "      <td>rēšˌîṯ</td>\n",
       "      <td>רֵאשִׁית</td>\n",
       "      <td>E70002</td>\n",
       "      <td>H7225</td>\n",
       "      <td>H7225</td>\n",
       "      <td>subs.f.sg.a</td>\n",
       "      <td>noun, feminine, singular, absolute</td>\n",
       "      <td>beginning</td>\n",
       "      <td>beginning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>the beginning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>בָּרָ֣א|</td>\n",
       "      <td>ברא|</td>\n",
       "      <td>bārā</td>\n",
       "      <td>bārˈā</td>\n",
       "      <td>ברא</td>\n",
       "      <td>E70003</td>\n",
       "      <td>H1254</td>\n",
       "      <td>H1254</td>\n",
       "      <td>verb.qal.perf.p3.m.sg</td>\n",
       "      <td>verb, qal, perfect, third person, masculine, singular</td>\n",
       "      <td>create</td>\n",
       "      <td>[he]+ create</td>\n",
       "      <td>4.0</td>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>אֱלֹהִ֑ים|</td>\n",
       "      <td>אלהים|</td>\n",
       "      <td>ʾĕlōhîm</td>\n",
       "      <td>ʔᵉlōhˈîm</td>\n",
       "      <td>אֱלֹהִים</td>\n",
       "      <td>E70004</td>\n",
       "      <td>H430</td>\n",
       "      <td>H430</td>\n",
       "      <td>subs.m.pl.a</td>\n",
       "      <td>noun, masculine, plural, absolute</td>\n",
       "      <td>god(s)</td>\n",
       "      <td>god [pl.]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>אֵ֥ת|</td>\n",
       "      <td>את|</td>\n",
       "      <td>ʾēt</td>\n",
       "      <td>ʔˌēṯ</td>\n",
       "      <td>אֵת</td>\n",
       "      <td>E70005</td>\n",
       "      <td>H853</td>\n",
       "      <td>H853</td>\n",
       "      <td>prep</td>\n",
       "      <td>preposition</td>\n",
       "      <td>[object marker]</td>\n",
       "      <td>[object marker]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the labeled data.\n",
    "display(HTML(updated_data.head().to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All string type columns in updated_data that have NaNs present.\n",
    "cols_with_NaN = [\n",
    "    \"paragraphMarker\",\n",
    "    \"poetryMarker\",\n",
    "    \"SBLstyleTransliteration\",\n",
    "    \"phoneticTranscription\",\n",
    "    \"StrongNumber\",\n",
    "    \"BSBgloss\"\n",
    "]\n",
    "\n",
    "# ---\n",
    "# Function to replace NaNs with values. \n",
    "def replace_NaNs():\n",
    "    for col in cols_with_NaN:\n",
    "        updated_data[col] = updated_data[col].replace({np.nan: \"\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Call function -> clean dataframe\n",
    "\n",
    "Note: I retained NaNs in the *BSBglossNode* column since it stores floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function.\n",
    "replace_NaNs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the final cleaned dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>BHS_wordNode</th>\n",
       "      <th>paragraphMarker</th>\n",
       "      <th>poetryMarker</th>\n",
       "      <th>KVJvsNode</th>\n",
       "      <th>KJVbook</th>\n",
       "      <th>KJVchapter</th>\n",
       "      <th>KJVverse</th>\n",
       "      <th>BHSvsNode</th>\n",
       "      <th>BHSbook</th>\n",
       "      <th>BHSchapter</th>\n",
       "      <th>BHSverse</th>\n",
       "      <th>clauseID</th>\n",
       "      <th>clauseKind</th>\n",
       "      <th>clauseType</th>\n",
       "      <th>language</th>\n",
       "      <th>BHS_wordPointed</th>\n",
       "      <th>BHS_wordConsonantal</th>\n",
       "      <th>SBLstyleTransliteration</th>\n",
       "      <th>phoneticTranscription</th>\n",
       "      <th>HebrewLexeme</th>\n",
       "      <th>lexemeID</th>\n",
       "      <th>StrongNumber</th>\n",
       "      <th>extendedStrongNumber</th>\n",
       "      <th>morphologyCode</th>\n",
       "      <th>morphologyDetail</th>\n",
       "      <th>ETCBCgloss</th>\n",
       "      <th>extendedGloss</th>\n",
       "      <th>BSBglossNode</th>\n",
       "      <th>BSBgloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>¶</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>בְּ|</td>\n",
       "      <td>ב|</td>\n",
       "      <td>bĕ</td>\n",
       "      <td>bᵊ</td>\n",
       "      <td>בְּ</td>\n",
       "      <td>E70001</td>\n",
       "      <td></td>\n",
       "      <td>H9003</td>\n",
       "      <td>prep</td>\n",
       "      <td>preposition</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>רֵאשִׁ֖ית|</td>\n",
       "      <td>ראשית|</td>\n",
       "      <td>rēšît</td>\n",
       "      <td>rēšˌîṯ</td>\n",
       "      <td>רֵאשִׁית</td>\n",
       "      <td>E70002</td>\n",
       "      <td>H7225</td>\n",
       "      <td>H7225</td>\n",
       "      <td>subs.f.sg.a</td>\n",
       "      <td>noun, feminine, singular, absolute</td>\n",
       "      <td>beginning</td>\n",
       "      <td>beginning</td>\n",
       "      <td>2.0</td>\n",
       "      <td>the beginning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>בָּרָ֣א|</td>\n",
       "      <td>ברא|</td>\n",
       "      <td>bārā</td>\n",
       "      <td>bārˈā</td>\n",
       "      <td>ברא</td>\n",
       "      <td>E70003</td>\n",
       "      <td>H1254</td>\n",
       "      <td>H1254</td>\n",
       "      <td>verb.qal.perf.p3.m.sg</td>\n",
       "      <td>verb, qal, perfect, third person, masculine, singular</td>\n",
       "      <td>create</td>\n",
       "      <td>[he]+ create</td>\n",
       "      <td>4.0</td>\n",
       "      <td>created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>אֱלֹהִ֑ים|</td>\n",
       "      <td>אלהים|</td>\n",
       "      <td>ʾĕlōhîm</td>\n",
       "      <td>ʔᵉlōhˈîm</td>\n",
       "      <td>אֱלֹהִים</td>\n",
       "      <td>E70004</td>\n",
       "      <td>H430</td>\n",
       "      <td>H430</td>\n",
       "      <td>subs.m.pl.a</td>\n",
       "      <td>noun, masculine, plural, absolute</td>\n",
       "      <td>god(s)</td>\n",
       "      <td>god [pl.]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Verbal clauses</td>\n",
       "      <td>x-qatal-X clause</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>אֵ֥ת|</td>\n",
       "      <td>את|</td>\n",
       "      <td>ʾēt</td>\n",
       "      <td>ʔˌēṯ</td>\n",
       "      <td>אֵת</td>\n",
       "      <td>E70005</td>\n",
       "      <td>H853</td>\n",
       "      <td>H853</td>\n",
       "      <td>prep</td>\n",
       "      <td>preposition</td>\n",
       "      <td>[object marker]</td>\n",
       "      <td>[object marker]</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display our newly cleaned and labeled data.\n",
    "display(HTML(updated_data.head().to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataframe Into a SQL Database\n",
    "\n",
    "Adam Baker used C++ to convert the BHSA corpus into a sql database. He outlines his work on his [site](https://www.adambaker.org/text-fabric-format.php) where he links the sql file as well as his GitHub repository. Rather than create a new database, I will add Eliran's data as new table in Adam's database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam's sql file.\n",
    "sql_file = '../data_files/bhsa.sqlite'\n",
    "con = sqlite3.connect(sql_file) \n",
    "# Convert the dataframe to a table called extended_data in the bhsa database. \n",
    "updated_data.to_sql(\n",
    "    \"extended_data\", \n",
    "    con=con, \n",
    "    if_exists='replace', \n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test OHB Data Against BHSA\n",
    "\n",
    "I want to compare values in the OHB data to the BHSA data, especially text values, to make sure that the data is usable and accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">TF-app:</b> <span title=\"rv2.4.0=#571428c995d309c43ff592f885a5ebb42a87be6f offline under ~/text-fabric-data\">~/text-fabric-data/annotation/app-bhsa/code</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv1.7.1=#f9f50075d169820af90524e89f573b54e0b1adb4 offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/bhsa/tf/2021</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv2.0=#d74f7b52866927c316dfcaa2ac89eb51ea59c5dc offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/phono/tf/2021</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b title=\"local release\">data:</b> <span title=\"rv2.0=#2fb9e94de8ffc07e9e515e3efa36e502f95bdcea offline under ~/text-fabric-data\">~/text-fabric-data/etcbc/parallels/tf/2021</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 9.1.1\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "122 features found and 0 ignored\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Text-Fabric:</b> <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"text-fabric-api\">Text-Fabric API 9.1.1</a>, <a target=\"_blank\" href=\"https://github.com/annotation/app-bhsa\" title=\"bhsa TF-app\">app-bhsa v3</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/about/searchusage.html\" title=\"Search Templates Introduction and Reference\">Search Reference</a><br><b>Data:</b> <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/0_home\" title=\"provenance of BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis\">BHSA</a>, <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/writing/hebrew.html\" title=\"How TF features represent text\">Character table</a>, <a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/0_home\" title=\"BHSA feature documentation\">Feature docs</a><br><b>Features:</b><br><details><summary><b>Parallel Passages</b></summary><b><i><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/parallels/blob/master/programs/parallels.ipynb\" title=\"~/text-fabric-data/etcbc/parallels/tf/2021/crossref.tf\">crossref</a></i></b><br></details><details><summary><b>BHSA = Biblia Hebraica Stuttgartensia Amstelodamensis</b></summary><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/book.tf\">book</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/book@ll\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/book@am.tf\">book@ll</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/chapter\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/chapter.tf\">chapter</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/code\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/code.tf\">code</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/det\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/det.tf\">det</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/domain\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/domain.tf\">domain</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/freq_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/freq_lex.tf\">freq_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/function\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/function.tf\">function</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/g_cons.tf\">g_cons</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_cons_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/g_cons_utf8.tf\">g_cons_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/g_lex.tf\">g_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/g_lex_utf8.tf\">g_lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/g_word.tf\">g_word</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/g_word_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/g_word_utf8.tf\">g_word_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gloss\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/gloss.tf\">gloss</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/gn\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/gn.tf\">gn</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/label\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/label.tf\">label</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/language\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/language.tf\">language</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/lex.tf\">lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/lex_utf8.tf\">lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ls\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/ls.tf\">ls</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nametype\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/nametype.tf\">nametype</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nme\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/nme.tf\">nme</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/nu\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/nu.tf\">nu</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/number\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/number.tf\">number</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/otype\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/otype.tf\">otype</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pargr\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/pargr.tf\">pargr</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pdp\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/pdp.tf\">pdp</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/pfm\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/pfm.tf\">pfm</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/prs.tf\">prs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_gn\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/prs_gn.tf\">prs_gn</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_nu\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/prs_nu.tf\">prs_nu</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/prs_ps\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/prs_ps.tf\">prs_ps</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/ps\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/ps.tf\">ps</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/qere.tf\">qere</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/qere_trailer.tf\">qere_trailer</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_trailer_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/qere_trailer_utf8.tf\">qere_trailer_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/qere_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/qere_utf8.tf\">qere_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rank_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/rank_lex.tf\">rank_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/rela\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/rela.tf\">rela</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/sp\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/sp.tf\">sp</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/st\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/st.tf\">st</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/tab\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/tab.tf\">tab</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/trailer.tf\">trailer</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/trailer_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/trailer_utf8.tf\">trailer_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/txt\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/txt.tf\">txt</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/typ\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/typ.tf\">typ</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/uvf\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/uvf.tf\">uvf</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbe\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/vbe.tf\">vbe</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vbs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/vbs.tf\">vbs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/verse\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/verse.tf\">verse</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/voc_lex.tf\">voc_lex</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/voc_lex_utf8\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/voc_lex_utf8.tf\">voc_lex_utf8</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vs\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/vs.tf\">vs</a><br><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/vt\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/vt.tf\">vt</a><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/mother\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/mother.tf\">mother</a></i></b><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/omap@ll\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/omap@2017-2021.tf\">omap@ll</a></i></b><br><b><i><a target=\"_blank\" href=\"https://etcbc.github.io/bhsa/features/oslots\" title=\"~/text-fabric-data/etcbc/bhsa/tf/2021/oslots.tf\">oslots</a></i></b><br></details><details><summary><b>Phonetic Transcriptions</b></summary><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/etcbc/phono/tf/2021/phono.tf\">phono</a><br><a target=\"_blank\" href=\"https://nbviewer.jupyter.org/github/etcbc/phono/blob/master/programs/phono.ipynb\" title=\"~/text-fabric-data/etcbc/phono/tf/2021/phono_trailer.tf\">phono_trailer</a><br></details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>tr.tf.ltr, td.tf.ltr, th.tf.ltr { text-align: left ! important;}\n",
       "tr.tf.rtl, td.tf.rtl, th.tf.rtl { text-align: right ! important;}\n",
       "@font-face {\n",
       "  font-family: \"Gentium Plus\";\n",
       "  src: local('Gentium Plus'), local('GentiumPlus'),\n",
       "    url('/server/static/fonts/GentiumPlus-R.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/GentiumPlus-R.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src: local('Ezra SIL'), local('EzraSIL'),\n",
       "    url('/server/static/fonts/SILEOT.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SBL Hebrew\";\n",
       "  src: local('SBL Hebrew'), local('SBLHebrew'),\n",
       "    url('/server/static/fonts/SBL_Hbrw.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SBL_Hbrw.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Estrangelo Edessa\";\n",
       "  src: local('Estrangelo Edessa'), local('EstrangeloEdessa');\n",
       "    url('/server/static/fonts/SyrCOMEdessa.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SyrCOMEdessa.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuran;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran'), local('AmiriQuran'),\n",
       "    url('/server/static/fonts/AmiriQuran.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuran.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: AmiriQuranColored;\n",
       "  font-style: normal;\n",
       "  font-weight: 400;\n",
       "  src: local('Amiri Quran Colored'), local('AmiriQuranColored'),\n",
       "    url('/server/static/fonts/AmiriQuranColored.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/AmiriQuranColored.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"Santakku\";\n",
       "  src: local('Santakku'),\n",
       "    url('/server/static/fonts/Santakku.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/Santakku.woff?raw=true') format('woff');\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "  font-family: \"SantakkuM\";\n",
       "  src: local('SantakkuM'),\n",
       "    url('/server/static/fonts/SantakkuM.woff') format('woff'),\n",
       "    url('https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SantakkuM.woff?raw=true') format('woff');\n",
       "}\n",
       "/* bypassing some classical notebook settings */\n",
       "div#notebook {\n",
       "  line-height: unset;\n",
       "}\n",
       "/* neutral text */\n",
       ".txtn,.txtn a:visited,.txtn a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* transcription text */\n",
       ".txtt,.txtt a:visited,.txtt a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* source text */\n",
       ".txto,.txto a:visited,.txto a:link {\n",
       "    font-family: serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* phonetic text */\n",
       ".txtp,.txtp a:visited,.txtp a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* original script text */\n",
       ".txtu,.txtu a:visited,.txtu a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    text-decoration: none;\n",
       "    color: var(--text-color);\n",
       "}\n",
       "/* hebrew */\n",
       ".txtu.hbo,.lex.hbo {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* syriac */\n",
       ".txtu.syc,.lex.syc {\n",
       "    font-family: \"Estrangelo Edessa\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* neo aramaic */\n",
       ".txtu.cld,.lex.cld {\n",
       "    font-family: \"CharisSIL-R\", sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* standard arabic */\n",
       ".txtu.ara,.lex.ara {\n",
       "    font-family: \"AmiriQuran\", sans-serif;\n",
       "    font-size: large;\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* cuneiform */\n",
       ".txtu.akk,.lex.akk {\n",
       "    font-family: Santakku, sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "/* greek */\n",
       ".txtu.grc,.lex.grc a:link {\n",
       "    font-family: Gentium, sans-serif;\n",
       "    font-size: medium;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       "a:hover {\n",
       "    text-decoration: underline | important;\n",
       "    color: #0000ff | important;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".rtl {\n",
       "    direction: rtl ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".ubd {\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".col {\n",
       "   display: inline-block;\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: var(--features);\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    padding: 2px;\n",
       "    margin: 2px;\n",
       "    direction: ltr;\n",
       "    unicode-bidi: embed;\n",
       "    border: var(--meta-width) solid var(--meta-color);\n",
       "    border-radius: var(--meta-width);\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -2px 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 2px 0px;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".tfsechead {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--tfsechead);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".structure {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: var(--structure);\n",
       "    unicode-bidi: embed;\n",
       "    text-align: start;\n",
       "}\n",
       ".comments {\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".nd, a:link.nd {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    color: var(--node);\n",
       "    vertical-align: super;\n",
       "    direction: ltr ! important;\n",
       "    unicode-bidi: embed;\n",
       "}\n",
       ".lex {\n",
       "  color: var(--lex-color);;\n",
       "}\n",
       ".children,.children.ltr {\n",
       "    display: flex;\n",
       "    border: 0;\n",
       "    background-color: #ffffff;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "}\n",
       ".children.stretch {\n",
       "    align-items: stretch;\n",
       "}\n",
       ".children.hor {\n",
       "    flex-flow: row nowrap;\n",
       "}\n",
       ".children.hor.wrap {\n",
       "    flex-flow: row wrap;\n",
       "}\n",
       ".children.ver {\n",
       "    flex-flow: column nowrap;\n",
       "}\n",
       ".children.ver.wrap {\n",
       "    flex-flow: column wrap;\n",
       "}\n",
       ".contnr {\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    justify-content: flex-start;\n",
       "    align-items: flex-start;\n",
       "    align-content: flex-start;\n",
       "    flex-flow: column nowrap;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding:  10px 2px 2px 2px;\n",
       "    margin: 16px 2px 2px 2px;\n",
       "    border-style: solid;\n",
       "    font-size: small;\n",
       "}\n",
       ".contnr.trm {\n",
       "    background-attachment: local;\n",
       "}\n",
       ".contnr.cnul {\n",
       "    padding:  0;\n",
       "    margin: 0;\n",
       "    border-style: solid;\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".contnr.cnul,.lbl.cnul {\n",
       "    border-color: var(--border-color-nul);\n",
       "    border-width: var(--border-width-nul);\n",
       "    border-radius: var(--border-width-nul);\n",
       "}\n",
       ".contnr.c0,.lbl.c0 {\n",
       "    border-color: var(--border-color0);\n",
       "    border-width: var(--border-width0);\n",
       "    border-radius: var(--border-width0);\n",
       "}\n",
       ".contnr.c1,.lbl.c1 {\n",
       "    border-color: var(--border-color1);\n",
       "    border-width: var(--border-width1);\n",
       "    border-radius: var(--border-width1);\n",
       "}\n",
       ".contnr.c2,.lbl.c2 {\n",
       "    border-color: var(--border-color2);\n",
       "    border-width: var(--border-width2);\n",
       "    border-radius: var(--border-width2);\n",
       "}\n",
       ".contnr.c3,.lbl.c3 {\n",
       "    border-color: var(--border-color3);\n",
       "    border-width: var(--border-width3);\n",
       "    border-radius: var(--border-width3);\n",
       "}\n",
       ".contnr.c4,.lbl.c4 {\n",
       "    border-color: var(--border-color4);\n",
       "    border-width: var(--border-width4);\n",
       "    border-radius: var(--border-width4);\n",
       "}\n",
       "span.plain {\n",
       "    display: inline-block;\n",
       "    white-space: pre-wrap;\n",
       "}\n",
       ".plain {\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".plain.l,.contnr.l,.contnr.l>.lbl {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".plain.r,.contnr.r,.contnr.r>.lbl {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".plain.lno,.contnr.lno,.contnr.lno>.lbl {\n",
       "    border-left-style: none\n",
       "}\n",
       ".plain.rno,.contnr.rno,.contnr.rno>.lbl {\n",
       "    border-right-style: none\n",
       "}\n",
       ".plain.l {\n",
       "    padding-left: 4px;\n",
       "    margin-left: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".plain.r {\n",
       "    padding-right: 4px;\n",
       "    margin-right: 2px;\n",
       "    border-width: var(--border-width-plain);\n",
       "}\n",
       ".lbl {\n",
       "    font-family: monospace;\n",
       "    margin-top: -24px;\n",
       "    margin-left: 20px;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 6px;\n",
       "    border-style: solid;\n",
       "    display: block;\n",
       "    color: var(--label)\n",
       "}\n",
       ".lbl.trm {\n",
       "    background-attachment: local;\n",
       "    margin-top: 2px;\n",
       "    margin-left: 2px;\n",
       "    padding: 2px 2px;\n",
       "    border-style: none;\n",
       "}\n",
       ".lbl.cnul {\n",
       "    font-size: xx-small;\n",
       "}\n",
       ".lbl.c0 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c1 {\n",
       "    font-size: small;\n",
       "}\n",
       ".lbl.c2 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c3 {\n",
       "    font-size: medium;\n",
       "}\n",
       ".lbl.c4 {\n",
       "    font-size: large;\n",
       "}\n",
       ".occs, a:link.occs {\n",
       "    font-size: small;\n",
       "}\n",
       "\n",
       "/* PROVENANCE */\n",
       "\n",
       "div.prov {\n",
       "\tmargin: 40px;\n",
       "\tpadding: 20px;\n",
       "\tborder: 2px solid var(--fog-rim);\n",
       "}\n",
       "div.pline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.p2line {\n",
       "\tmargin-left: 2em;\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "}\n",
       "div.psline {\n",
       "\tdisplay: flex;\n",
       "\tflex-flow: row nowrap;\n",
       "\tjustify-content: stretch;\n",
       "\talign-items: baseline;\n",
       "\tbackground-color: var(--gold-mist-back);\n",
       "}\n",
       "div.pname {\n",
       "\tflex: 0 0 5rem;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.pval {\n",
       "    flex: 1 1 auto;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--node:               hsla(120, 100%,  20%, 1.0  );\n",
       "\t--label:              hsla(  0, 100%,  20%, 1.0  );\n",
       "\t--tfsechead:          hsla(  0, 100%,  25%, 1.0  );\n",
       "\t--structure:          hsla(120, 100%,  25%, 1.0  );\n",
       "\t--features:           hsla(  0,   0%,  30%, 1.0  );\n",
       "  --text-color:         hsla( 60,  80%,  10%, 1.0  );\n",
       "  --lex-color:          hsla(220,  90%,  60%, 1.0  );\n",
       "  --meta-color:         hsla(  0,   0%,  90%, 0.7  );\n",
       "  --meta-width:         3px;\n",
       "  --border-color-nul:   hsla(  0,   0%,  90%, 0.5  );\n",
       "  --border-color0:      hsla(  0,   0%,  90%, 0.9  );\n",
       "  --border-color1:      hsla(  0,   0%,  80%, 0.9  );\n",
       "  --border-color2:      hsla(  0,   0%,  70%, 0.9  );\n",
       "  --border-color3:      hsla(  0,   0%,  80%, 0.8  );\n",
       "  --border-color4:      hsla(  0,   0%,  60%, 0.9  );\n",
       "  --border-width-nul:   2px;\n",
       "  --border-width0:      2px;\n",
       "  --border-width1:      3px;\n",
       "  --border-width2:      4px;\n",
       "  --border-width3:      6px;\n",
       "  --border-width4:      5px;\n",
       "  --border-width-plain: 2px;\n",
       "}\n",
       ".hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 2px;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "div.contnr.hl,div.lbl.hl {\n",
       "  background-color: var(--hl-strong);\n",
       "}\n",
       "div.contnr.hl {\n",
       "  border-color: var(--hl-rim) ! important;\n",
       "\tborder-width: 4px ! important;\n",
       "}\n",
       "\n",
       "span.hlbx {\n",
       "\tborder-color: var(--hl-rim);\n",
       "\tborder-width: 4px ! important;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 6px;\n",
       "  padding: 4px;\n",
       "  margin: 4px;\n",
       "}\n",
       "\n",
       "span.plain {\n",
       "  display: inline-block;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55,  80%,  50%, 1.0  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Text-Fabric API:</b> names <a target=\"_blank\" href=\"https://annotation.github.io/text-fabric/tf/cheatsheet.html\" title=\"doc\">N F E L T S C TF</a> directly usable</div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the BHSA API\n",
    "A = use('bhsa', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare consonantal, pointed, and lexeme word forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load SQL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To execute queries. \n",
    "sql_file = '../data_files/bhsa.sqlite'\n",
    "con = sqlite3.connect(sql_file) \n",
    "\n",
    "# Words from new SQL database.\n",
    "sql_pointed = con.execute(\n",
    "    \"SELECT BHS_wordPointed FROM extended_data\"\n",
    "    ).fetchall()\n",
    "sql_consonant = con.execute(\n",
    "    \"SELECT BHS_wordConsonantal FROM extended_data\"\n",
    "    ).fetchall()\n",
    "sql_lexeme = con.execute(\n",
    "    \"SELECT HebrewLexeme FROM extended_data\"\n",
    "    ).fetchall()\n",
    "\n",
    "# Convert tuples to lists.\n",
    "sql_pointed = [i[0] for i in sql_pointed]\n",
    "sql_consonant = [i[0] for i in sql_consonant]\n",
    "sql_lexeme = [i[0] for i in sql_lexeme]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Function that goes through all word-type nodes in the \n",
    "# BHSA and compares them to words in Eliran's data. \n",
    "def check_text():\n",
    "    # Values used to realign OHB data to \n",
    "    # BHSA where rows are missing.\n",
    "    j = -1\n",
    "    k = 0\n",
    "    # Iterate over all words in BHSA. Stop at 426581,\n",
    "    # the max node in SQL, there are a few more in BHS.\n",
    "    for word in F.otype.s('word')[:426581]:\n",
    "\n",
    "        # BHSA node count starts at 1. \n",
    "        i = word + j\n",
    "        # Prevent closed loop.\n",
    "        i = i+1 if i == k else i\n",
    "\n",
    "        # -- Make sure the data stays aligned --\n",
    "        # See \"Textual mismatch notes\" to understand. \n",
    "        # Catch missing node in OHB data.\n",
    "        if word == 16564:\n",
    "            j -= 1\n",
    "        # Catch instances of doubles.\n",
    "        dup_check = sql_consonant[i].split('|')[0]\n",
    "        if dup_check in doubles:\n",
    "            j -= 1\n",
    "            k = i\n",
    "            doubles[dup_check].append(word)\n",
    "        # OHB node 392490 takes the place of three \n",
    "        # nodes in BHSA: 392490 - 392492, so we \n",
    "        # increment j by 2 to preserve alignment.\n",
    "        if dup_check == \"חצי המנחות\":\n",
    "            j -= 2\n",
    "            k = i\n",
    "        \n",
    "        # -- Perform comparisons and update lists --\n",
    "        # Compare pointed.\n",
    "        sql_pt =  sql_pointed[i].split('|')[0]\n",
    "        bhs_pt = F.g_word_utf8.v(word)\n",
    "        if sql_pt != bhs_pt:\n",
    "            pointed_mismatches.append(\n",
    "                f\"{word} - BHSA:{bhs_pt} | SQL:{sql_pt}\")\n",
    "        # Compare pointed extension. \n",
    "        sql_pt_xt = sql_pointed[i].replace('|', '')\n",
    "        bhs_pt_xt = T.text(word, fmt='text-orig-full')\n",
    "        if sql_pt_xt != bhs_pt_xt :\n",
    "            pointed_ext_mismatches.append(\n",
    "                f\"{word} - BHSA:{bhs_pt_xt} | SQL:{sql_pt_xt}\")\n",
    "        # Compare consonsantal.\n",
    "        sql_cs =  sql_consonant[i].split('|')[0]\n",
    "        bhs_cs = F.g_cons_utf8.v(word)\n",
    "        if bhs_cs != sql_cs:\n",
    "            consonant_mismatches.append(\n",
    "                f\"{word} - BHSA:{bhs_cs} | SQL:{sql_cs}\")\n",
    "        # Compare consonantal extension. \n",
    "        sql_cs_xt = sql_consonant[i].replace('|', '')\n",
    "        bhs_cs_xt = T.text(word, fmt='text-orig-plain')\n",
    "        if bhs_cs_xt != sql_cs_xt:\n",
    "            consonant_ext_mismatches.append(\n",
    "                f\"{word} - BHSA:{bhs_cs_xt} | SQL:{sql_cs_xt}\")\n",
    "        # Compare lexeme.\n",
    "        sql_lex = sql_lexeme[i]\n",
    "        bhs_lex = F.g_lex_utf8.v(word)\n",
    "        if bhs_lex != sql_lex:\n",
    "            lexeme_mismatches.append(\n",
    "                f\"{word} - BHSA:{bhs_lex} | SQL:{sql_lex}\")\n",
    "\n",
    "\n",
    "# ---\n",
    "# Convert all of the mismatch data into a dataframe. \n",
    "def display_mismatches():\n",
    "    # Create individual dataframes.\n",
    "    pointed = pd.DataFrame(\n",
    "        pointed_mismatches, \n",
    "        columns =['Pointed'])\n",
    "    pointed_xt = pd.DataFrame(\n",
    "        pointed_ext_mismatches, \n",
    "        columns =['Pointed-ext'])\n",
    "    consonantal = pd.DataFrame(\n",
    "        consonant_mismatches, \n",
    "        columns =['Consonantal'])\n",
    "    consonantal_xt = pd.DataFrame(\n",
    "        consonant_ext_mismatches, \n",
    "        columns =['Consonantal-ext'])\n",
    "    lexeme = pd.DataFrame(\n",
    "        lexeme_mismatches, \n",
    "        columns =['Lexeme'])\n",
    "    # Put them together.\n",
    "    text_mismatches = pd.concat(\n",
    "                    [pointed, \n",
    "                    pointed_xt, \n",
    "                    consonantal, \n",
    "                    consonantal_xt,\n",
    "                    lexeme], \n",
    "                    axis=1)\n",
    "    \n",
    "    return text_mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Call functions -> populate mismatch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catch all instances of ארם נהרים.\n",
    "doubles = {\n",
    "    \"ארם נהרים\": [],\n",
    "    \"ארם מעכה\": [] \n",
    "}\n",
    "\n",
    "# Lists to hold mismatches.\n",
    "pointed_mismatches = []\n",
    "pointed_ext_mismatches = []\n",
    "consonant_mismatches = []\n",
    "consonant_ext_mismatches = []\n",
    "lexeme_mismatches = []\n",
    "\n",
    "# Compare data.\n",
    "check_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create dataframe to visualize mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mismatch dataframe.\n",
    "text_mismatches = display_mismatches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize the mismatch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pointed</th>\n",
       "      <th>Pointed-ext</th>\n",
       "      <th>Consonantal</th>\n",
       "      <th>Consonantal-ext</th>\n",
       "      <th>Lexeme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1 - BHSA:בְּ | SQL:רֵאשִׁ֖ית</td>\n",
       "      <td>1 - BHSA:בְּ | SQL:רֵאשִׁ֖ית</td>\n",
       "      <td>1 - BHSA:ב | SQL:ראשית</td>\n",
       "      <td>1 - BHSA:ב | SQL:ראשית</td>\n",
       "      <td>1 - BHSA:בְּ | SQL:רֵאשִׁית</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3897 - BHSA:הוצא | SQL:הַיְצֵ֣א</td>\n",
       "      <td>7138 - BHSA:בֵינֶֽיׄךָ׃  | SQL:בֵינֶֽיׄכָ׃</td>\n",
       "      <td>2 - BHSA:ראשׁית | SQL:ראשית</td>\n",
       "      <td>2 - BHSA:ראשׁית  | SQL:ראשית</td>\n",
       "      <td>3 - BHSA:בָּרָא | SQL:ברא</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420 - BHSA:אהלה | SQL:אָהֳלֹֽו</td>\n",
       "      <td>11325 - BHSA:אֲרַ֥ם  | SQL:אֲרַ֥ם נַֽהֲרַ֖יִם</td>\n",
       "      <td>7 - BHSA:שׁמים | SQL:שמים</td>\n",
       "      <td>7 - BHSA:שׁמים  | SQL:שמים</td>\n",
       "      <td>4 - BHSA:אֱלֹה | SQL:אֱלֹהִים</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5645 - BHSA:אהלה | SQL:אָהֳלֹ֑ו</td>\n",
       "      <td>11326 - BHSA:נַֽהֲרַ֖יִם  | SQL:אֶל־</td>\n",
       "      <td>20 - BHSA:חשׁך | SQL:חשך</td>\n",
       "      <td>11 - BHSA:ארץ׃  | SQL:ארץ</td>\n",
       "      <td>7 - BHSA:שָּׁמַי | SQL:שָׁמַיִם</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5912 - BHSA:אהלה | SQL:אָֽהֳלֹו֙</td>\n",
       "      <td>16564 - BHSA: | SQL:חֲלֹ֖ום</td>\n",
       "      <td>57 - BHSA:חשׁך | SQL:חשך</td>\n",
       "      <td>20 - BHSA:חשׁך  | SQL:חשך</td>\n",
       "      <td>10 - BHSA:הָ | SQL:הַ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6246 - BHSA:צביים | SQL:צְבֹויִ֔ם</td>\n",
       "      <td>71532 - BHSA:אַׄהֲׄרֹ֛ׄןׄ  | SQL:אַׄהֲׄרֹ֛ׄנׄ</td>\n",
       "      <td>68 - BHSA:חשׁך | SQL:חשך</td>\n",
       "      <td>21 - BHSA:על־ | SQL:על</td>\n",
       "      <td>11 - BHSA:אָרֶץ | SQL:אֶרֶץ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6354 - BHSA:צביים | SQL:צְבֹויִ֔ם</td>\n",
       "      <td>76767 - BHSA:מַּחֲנֶֽה׃ נ ס  | SQL:מַּחֲנֶֽה׃ ׆ ס</td>\n",
       "      <td>96 - BHSA:יעשׂ | SQL:יעש</td>\n",
       "      <td>28 - BHSA:על־ | SQL:על</td>\n",
       "      <td>13 - BHSA:הָ | SQL:הַ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7138 - BHSA:בֵינֶֽיׄךָ | SQL:בֵינֶֽיׄכָ</td>\n",
       "      <td>76795 - BHSA:יִשְׂרָאֵֽל׃ נ פ  | SQL:יִשְׂרָאֵֽל׃ ׆ פ</td>\n",
       "      <td>106 - BHSA:אשׁר | SQL:אשר</td>\n",
       "      <td>31 - BHSA:מים׃  | SQL:מים</td>\n",
       "      <td>14 - BHSA:אָרֶץ | SQL:אֶרֶץ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11325 - BHSA:אֲרַ֥ם | SQL:אֲרַ֥ם נַֽהֲרַ֖יִם</td>\n",
       "      <td>88141 - BHSA:עִשָּׂרֹוׄן֙  | SQL:עִשָּׂרֹוׄנ֙</td>\n",
       "      <td>116 - BHSA:אשׁר | SQL:אשר</td>\n",
       "      <td>38 - BHSA:יהי־ | SQL:יהי</td>\n",
       "      <td>15 - BHSA:הָי | SQL:היה</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11326 - BHSA:נַֽהֲרַ֖יִם | SQL:אֶל</td>\n",
       "      <td>105982 - BHSA:אֲרַ֥ם  | SQL:אֲרַ֥ם נַהֲרַ֖יִם</td>\n",
       "      <td>131 - BHSA:שׁמים | SQL:שמים</td>\n",
       "      <td>39 - BHSA:אור׃  | SQL:אור</td>\n",
       "      <td>16 - BHSA:תֹהוּ | SQL:תֹּהוּ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display head.\n",
    "display(HTML(text_mismatches.head(10).to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save dataframe locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-meaningful data.\n",
    "# (See notes at the end to see why they are meaningless)\n",
    "text_mismatches = text_mismatches.drop(\n",
    "    columns=[\n",
    "        \"Pointed\",\n",
    "        \"Consonantal\",\n",
    "        \"Consonantal-ext\",\n",
    "        \"Lexeme\"])\n",
    "\n",
    "# Drop the extra rows. \n",
    "text_mismatches.dropna(\n",
    "    # subset = [\"Pointed\"],\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a txt file.\n",
    "save_to = \"../data_files/mismatches.txt\"\n",
    "text_mismatches.to_csv(\n",
    "    save_to,\n",
    "    sep='\\t',\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to visualize BHSA nodes after comparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# Function to get BHSA words in a range of the\n",
    "# mismatched OHB node. \n",
    "def bhsa_in_range(i):\n",
    "    nodes = []\n",
    "    # start preceeding nodes and end following nodes.\n",
    "    start= -6\n",
    "    end= 2\n",
    "    for j in range(start, end):\n",
    "        nodes.append(i+j)\n",
    "    # Display the node in it's Scripture context.\n",
    "    for n in nodes:\n",
    "        print(\"Node:\", n)\n",
    "        A.plain(n)\n",
    "\n",
    "# Call function\n",
    "# bhsa_in_range(16562)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual mismatch notes\n",
    "```Note: all references to 'node' follow the *BHA_wordNode* value. If there is a mismatch I will include BHSA node values in parentheses.```\n",
    "\n",
    "**Pointed text differences**\n",
    "- Places where the BHSA lacks text markings that are included in Leningrad Codex (WLC), following the BHS, OHB chose the WLC form. For example, at node 4420, in Gen 9:21, [BHS renders](https://www.academic-bible.com/en/online-bibles/biblia-hebraica-stuttgartensia-bhs/read-the-bible-text/bibel/text/lesen/stelle/1/90001/99999/ch/df5b28ecb57b22ae25d0ce157bea69ca/) tent as אהלה while [WLC renders](https://www.bible.com/bible/904/GEN.9.WLC) it as אָהֳלֹֽה. *Note that the text displayed using the BHSA API function T.text(4420) actually does display אָהֳלֹֽו.* However, OHB's rendering of node 4420 matches neither of these because his ends in a *vav*: אָהֳלֹֽו.\n",
    "- There are places where OHB fails to place the ending consonant in its sofit form. E.g., at node 7138 it has בֵינֶֽיׄכָ instead of the BHSA's בֵינֶֽיׄךָ. \n",
    "- **Major Error:** Non-aligned & missing data -> offset.\n",
    "    - At node 11325 OHB combines two words (BHSA 11325, 11326), causing all the remaining nodes to be offset by 1. OHB has אֲרַ֥ם נַֽהֲרַ֖יִם where the BHSA has אֲרַ֥ם. BHSA node 11326 is נַֽהֲרַ֖יִם. This same thing also occurs at nodes 105980, 128870, 320251, and 401286 (BHSA 105982, 128873, 320255, 401293; notice the offset increases each time, by 2, 3, ...). This offset occurs similarly at 401289 with the words אֲרַ֤ם מַעֲכָה֙ (BHSA 401297 and 401298).\n",
    "    - At nodes 16562 to 16563 (BHSA 16563, 16564, 16565) the OHB data jumps from בַּ to חֲלֹ֖ום, missing a row in the middle where BHSA has a node (BHSA 16564) for the embedded *he* (הָ) in בַּ. This again causes an offset. \n",
    "    - At node 392485 (BHSA 392490), the OHB has חֲצִי הַמְּנֻחֹות which takes the place of three nodes in BHSA (392490, 392491, 392492).\n",
    "\n",
    "**Consonantal text differences:** \n",
    "- The BHSA includes the difference between *shin* and *sin*, whereas OHB data doesn't. For example, at node 72 the BHSA has יעשׂ while the SQL data has יעש. In this, OHB reflects common practice with consonantal Hebrew, e.g., [Sefaria](https://www.sefaria.org/Genesis.1.12?lang=bi&aliyot=0).\n",
    "- The BHSA includes extensions (see *text_extensions* list in the \"Clean Text and Clause Data\" section), whereas OHB only preserves spaces. For example, at node 11 (the end of Gen 1:1), the BHSA has ארץ׃ while the OHB has ארץ without the sof pasuk (׃).\n",
    "\n",
    "**Lexeme text differences:** The BHSA differs with both letters and vowels. Some example nodes are:\n",
    "```\n",
    "- 95  BHSA:וַ   | SQL:וְ \n",
    "- 96  BHSA:עַשׂ  | SQL:עשׂה \n",
    "- 97  BHSA:אֱלֹה | SQL:אֱלֹהִים \n",
    "- 98  BHSA:אֶת  | SQL:אֵת \n",
    "- 99  BHSA:הָ   | SQL:הַ \n",
    "```\n",
    "\n",
    "### Summary\n",
    "We end up with about 221 differences for the pointed text. Some are significant, but many have to do with accent marks. (**Note** that \"significant\" refers to the ability to query items associated with a specific word node. The entire BHS visible text is still present to render in an app, but the lack of node-id alignment with BHSA could make certain queries difficult). There are many more differences with the consonants, which are not of concern because OHB follows the common form. There are many lexeme differences which may be of concern. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
